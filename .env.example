# Etherpad Plus - Environment Configuration Example
# Copy this file to .env and customize the values

# ===== Application Settings =====

# Port Configuration
# Published port (accessible on host)
DOCKER_COMPOSE_APP_PORT_PUBLISHED=9001
# Target port (inside container)
DOCKER_COMPOSE_APP_PORT_TARGET=9001

# Admin Panel Password
# Change this for production!
DOCKER_COMPOSE_APP_ADMIN_PASSWORD=changeme

# Default Pad Text
# IMPORTANT: This variable cannot be empty in latest Etherpad versions
DOCKER_COMPOSE_APP_DEFAULT_PAD_TEXT="Welcome to Etherpad Plus"

# Optional Application Settings
# DOCKER_COMPOSE_APP_DB_CHARSET=utf8mb4
# DOCKER_COMPOSE_APP_DISABLE_IP_LOGGING=false
# DOCKER_COMPOSE_APP_SOFFICE=null
# DOCKER_COMPOSE_APP_TRUST_PROXY=true

# ===== PostgreSQL Database Settings =====

# Database Name
DOCKER_COMPOSE_POSTGRES_DATABASE=etherpad

# Database User
DOCKER_COMPOSE_POSTGRES_USER=etherpad

# Database Password
# Change this for production!
DOCKER_COMPOSE_POSTGRES_PASSWORD=changeme

# Database Port (internal network only)
# DOCKER_COMPOSE_POSTGRES_PORT=5432

# ===== Notes =====

# 1. After creating .env, load variables in your terminal:
#    source .env
#
# 2. Default values are defined in compose.yml
#
# 3. Never commit .env to version control
#
# 4. For production deployments:
#    - Use strong passwords
#    - Consider using Docker secrets
#    - Configure reverse proxy for TLS
#    - Set TRUST_PROXY=true if behind proxy

DOCKER_COMPOSE_APP_ETHERPAD_FQDN=

DOCKER_COMPOSE_APP_SOFFICE_PATH='/usr/bin/soffice'

# ===== LanguageTool Settings =====

# Port Configuration
DOCKER_COMPOSE_LANGTOOL_PORT_PUBLISHED=8081
# DOCKER_COMPOSE_LANGTOOL_PORT_TARGET=8081

# N-gram Data Configuration
# Comma-separated language codes: en, de, es, fr, nl
# Set to "none" to disable automatic downloads (default)
# Examples:
#   DOCKER_COMPOSE_LANGTOOL_NGRAM_LANGS=en
#   DOCKER_COMPOSE_LANGTOOL_NGRAM_LANGS=en,de,fr
DOCKER_COMPOSE_LANGTOOL_NGRAM_LANGS=none

# Note: N-gram data is large (~8GB for English)
# - First startup will take time to download
# - Data is stored in Docker volume 'languagetool_ngrams'
# - For manual setup: place extracted data in volume at /ngrams/<lang>/
#   (e.g., /ngrams/en/, /ngrams/de/)

# ===== AI Assistant Settings =====

# AI Provider: "ollama" or "openrouter"
AI_PROVIDER=ollama

# Ollama Configuration
# URL to your Ollama instance (if running in Docker, use service name)
OLLAMA_API_URL=http://ollama:11434
# Model to use (e.g., llama2, mistral, codellama)
OLLAMA_MODEL=llama2

# OpenRouter Configuration
# Get API key from https://openrouter.ai/keys
OPENROUTER_API_KEY=
# Model identifier (e.g., openai/gpt-3.5-turbo, anthropic/claude-3-haiku)
OPENROUTER_MODEL=openai/gpt-3.5-turbo

# Note: AI Assistant requires either:
# - Ollama running and accessible at OLLAMA_API_URL, OR
# - Valid OpenRouter API key set in OPENROUTER_API_KEY
# Set AI_PROVIDER to choose which one to use
